{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Kaggle Kernel\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "003f53f487787cd05a8bf1ce3adfa43cf19dd6ac"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "080cc6781b955431d304374cdd51ff568e2bb7bf"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0e5fc482c22d544eed1a73677e4d58d0f292205"
   },
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12909c43c28b01b3cbde34c9cc9ea29250695ed1"
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08dab9792e68a0e0982ba935508f82cb4f708498"
   },
   "outputs": [],
   "source": [
    "#train['none'] = 1-train[label_cols].max(axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e322d22fa23c4586ff0d87938ac939dba9a648c5"
   },
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "# Make text into lower case, remove \\n, numbers, extra spaces, punctuation and so on.\n",
    "def prepare_for_char_n_gram(text):\n",
    "\n",
    "    clean = bytes(text.lower(), encoding=\"utf-8\")\n",
    "    clean = clean.replace(b\"\\n\", b\" \")\n",
    "    clean = clean.replace(b\"\\t\", b\" \")\n",
    "    clean = clean.replace(b\"\\b\", b\" \")\n",
    "    clean = clean.replace(b\"\\r\", b\" \")\n",
    "    \n",
    "    exclude = re.compile(b'[%s]' % re.escape(bytes(string.punctuation, encoding='utf-8')))\n",
    "    clean = b\" \".join([exclude.sub(b'', token) for token in clean.split()])\n",
    "    clean = re.sub(b\"\\d+\", b\" \", clean)\n",
    "    clean = re.sub(b'\\s+', b' ', clean)\n",
    "    clean = re.sub(b'\\s+$', b'', clean)\n",
    "    \n",
    "    return str(clean, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "793cf28e23a3712683e7eedab248d6ab002888cb"
   },
   "outputs": [],
   "source": [
    "#On cleaning the data, the model did not perform as well, so commented it out.\n",
    "# train[\"comment_text\"] = train[\"comment_text\"].apply(lambda x: prepare_for_char_n_gram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f97cbd68ceb480e4045e77a0e2c408b0ab3e8b5"
   },
   "outputs": [],
   "source": [
    "# test[\"comment_text\"] = test[\"comment_text\"].apply(lambda x: prepare_for_char_n_gram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ae0050ffdd431beca2637c405ec3fcfdb6491b4"
   },
   "outputs": [],
   "source": [
    "#Find length of regex\n",
    "def count_regexp_occ(regexp=\"\", text=None):\n",
    "    return len(re.findall(regexp, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c95d63626574a3d03ab95cce5e05ccd246b1b15"
   },
   "outputs": [],
   "source": [
    "def get_indicators_and_clean_comments(df):\n",
    "    # Count number of \\n\n",
    "    df[\"ant_slash_n\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\n\", x))\n",
    "    # Get length in words and characters\n",
    "    df[\"raw_word_len\"] = df[\"comment_text\"].apply(lambda x: len(x.split()))\n",
    "    df[\"raw_char_len\"] = df[\"comment_text\"].apply(lambda x: len(x))\n",
    "    # Check number of upper case, if you're angry you may write in upper case\n",
    "    df[\"nb_upper\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[A-Z]\", x))\n",
    "    # Number of F words - f..k contains folk, fork,\n",
    "    df[\"nb_fk\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ff]\\S{2}[Kk]\", x))\n",
    "    # Number of S word\n",
    "    df[\"nb_sk\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ss]\\S{2}[Kk]\", x))\n",
    "    # Number of D words\n",
    "    df[\"nb_dk\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[dD]ick\", x))\n",
    "    # Number of occurence of You, insulting someone usually needs someone called : you\n",
    "    df[\"nb_you\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\W[Yy]ou\\W\", x))\n",
    "    # Reference to mother ;-)\n",
    "    df[\"nb_mother\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\Wmother\\W\", x))\n",
    "    # Just checking for toxic 19th century vocabulary\n",
    "    df[\"nb_ng\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\Wnigger\\W\", x))\n",
    "    # Some Sentences start with a <:> so it may help\n",
    "    df[\"start_with_columns\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"^\\:+\", x))\n",
    "    # Check for time stamp\n",
    "    df[\"has_timestamp\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\d{2}|:\\d{2}\", x))\n",
    "    # Check for dates 18:44, 8 December 2010\n",
    "    df[\"has_date_long\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\D\\d{2}:\\d{2}, \\d{1,2} \\w+ \\d{4}\", x))\n",
    "    # Check for date short 8 December 2010\n",
    "    df[\"has_date_short\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\D\\d{1,2} \\w+ \\d{4}\", x))\n",
    "    # Check for http links\n",
    "    df[\"has_http\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"http[s]{0,1}://\\S+\", x))\n",
    "    # check for mail\n",
    "    df[\"has_mail\"] = df[\"comment_text\"].apply(\n",
    "        lambda x: count_regexp_occ(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', x)\n",
    "    )\n",
    "    # Looking for words surrounded by == word == or \"\"\"\" word \"\"\"\"\n",
    "    df[\"has_emphasize_equal\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\={2}.+\\={2}\", x))\n",
    "    df[\"has_emphasize_quotes\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\\"{4}\\S+\\\"{4}\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f577cef3390dc4eca9f2a7ecde591b3e4d3fd880"
   },
   "outputs": [],
   "source": [
    "get_indicators_and_clean_comments(train)\n",
    "get_indicators_and_clean_comments(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4abb30c7256a0226c2c8549b490716a79a80c37d"
   },
   "outputs": [],
   "source": [
    "num_features = [f_ for f_ in train.columns\n",
    "                    if f_ not in [\"comment_text\", \"clean_comment\", \"id\", \"remaining_chars\",\n",
    "                                      'has_ip_address'] + label_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85c4e38a89e809fe2c81379557275c528ac3856b"
   },
   "outputs": [],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling and converting to CSR sparse representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4614a2cbe08aca3209290f38daf84d4842f65fd4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac407d6f039c02d078ad66799bb3c4fefd3fc49a"
   },
   "outputs": [],
   "source": [
    "skl = MinMaxScaler()\n",
    "train_num_features = csr_matrix(skl.fit_transform(train[num_features]))\n",
    "test_num_features = csr_matrix(skl.fit_transform(test[num_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d148c0e22cafa693a20710f1d197e496b10da880"
   },
   "outputs": [],
   "source": [
    "train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbec5be5628c8902bcee01dfa6857ae4e96c8e2a"
   },
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98584465bcb2e0a7a59ac642fe22a390fa09afab"
   },
   "outputs": [],
   "source": [
    "trn_term_doc = word_vectorizer.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "046fcebe94bc0c93a6df01701bc127704acf1543"
   },
   "outputs": [],
   "source": [
    "test_term_doc = word_vectorizer.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack the new features and the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f50f8310ac3e221f93ba769fad6b261550a738a"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e6b9f70783fc1dceee25ea7295486c910fc2484"
   },
   "outputs": [],
   "source": [
    "csr_trn = hstack(\n",
    "            [\n",
    "                trn_term_doc,\n",
    "                train_num_features\n",
    "            ]\n",
    "        ).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "109e29642883e19987603ecf49e2d4122f6f0821"
   },
   "outputs": [],
   "source": [
    "csr_sub = hstack(\n",
    "            [\n",
    "                test_term_doc,\n",
    "                test_num_features\n",
    "            ]\n",
    "        ).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06a1ee34ad478b192c6bbd12c1cd248bb6c148ae"
   },
   "outputs": [],
   "source": [
    "Y_train=train.iloc[:,2:9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7446870c009e71dc50283b285c9e039651572cb0"
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fe080021d027b0edc13cf615f4c14af62cca36d"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#X=trn_term_doc.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fdca353b9412b634b6db42c3668647134b633c6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X=csr_trn.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6317d43e2c06f9b8f6e929bebce7b8d61509370a"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#Y=test_term_doc.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccd496ab5937bdc74e2a1103b45d31840fd4e10b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Y=csr_sub.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8add1acb1498a2d5c36dea140cb8d35551ffc47"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bad64109a67d16516836f390031705668ec5c9f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def getpredictionXGB(X,X_test):\n",
    "    my_model = XGBRegressor()\n",
    "    return my_model.fit(X, X_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b428932a9d0d490a1cfeb213f73e54205443d214"
   },
   "outputs": [],
   "source": [
    "predi = np.zeros((len(test), len(label_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71bfb752ee8a65871491ff17d491fae1b9549a28"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,j in enumerate(label_cols):\n",
    "    classifier=getpredictionXGB(X,train[j])\n",
    "    ##predi[i]=rating\n",
    "    predi[:,i]=classifier.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "916aad2a627904f2fe27f2ec9a44d024a65ef873"
   },
   "outputs": [],
   "source": [
    "submid = pd.DataFrame({'id': test[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(predi, columns = label_cols)], axis=1)\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
